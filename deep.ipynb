{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 298 files belonging to 2 classes.\n",
      "7\n",
      "2\n",
      "1\n",
      "10\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 146\u001b[0m\n\u001b[0;32m    143\u001b[0m tensorboard_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(log_dir \u001b[39m=\u001b[39m logdir)\n\u001b[0;32m    145\u001b[0m \u001b[39m#epochs are how many runs we do over a training set. we pass over our training data to run an evaluation on our evaluation data and we want to log our information to tensorboard\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m val, callbacks \u001b[39m=\u001b[39;49m [tensorboard_callback])\n\u001b[0;32m    148\u001b[0m \u001b[39m#now we are totally trained\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \n\u001b[0;32m    150\u001b[0m \u001b[39m#visual loss and data loss\u001b[39;00m\n\u001b[0;32m    151\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n",
      "File \u001b[1;32mc:\\Users\\mason\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mason\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\mason\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mason\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mason\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:959\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    956\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    958\u001b[0m     \u001b[39m# no_variable_creation function.\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    960\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    962\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_function_spec  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    963\u001b[0m       \u001b[39m.\u001b[39mcanonicalize_function_inputs(\n\u001b[0;32m    964\u001b[0m           args, kwds))\n",
      "File \u001b[1;32mc:\\Users\\mason\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\mason\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mason\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\mason\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "First machine learning program following tutorial https://www.youtube.com/watch?v=jztwpsIzEGc&t=1800s\n",
    "\n",
    "Program that uses machine learning in order to differentiate 2 folders of images\n",
    "\n",
    "In this case I am going to differentiate basketball players and lacrosse players\n",
    "\n",
    "All that is needed is a folders change in the data folder and we can differentiate whatever we want\n",
    "\n",
    "0 is basketball and a 1 is lacrosse\n",
    "\n",
    "IMGHDR cannot be used as in the tutorial so we use cv2 instead as seen around line 50\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#imports\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "\n",
    "\n",
    "#avoid out of memory and vram errors\n",
    "#cannot find a single GPU, may be an issue later\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "#variable to hold path to data directory\n",
    "data_dir = 'data'\n",
    "\n",
    "#makes our good image exts\n",
    "image_exts = ['jpeg','bmp','png']\n",
    "\n",
    "\n",
    "#takes out bad images\n",
    "#MAY NEED IMGHDR HERE\n",
    "#lacrosse and basketball are image classes\n",
    "for image_class in os.listdir(data_dir):\n",
    "    #for each image in those directories\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        #gets image path\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            #reads in the image and creats a form variable that will give us some sort of .jpg .png etc\n",
    "            img = cv2.imread(image_path)\n",
    "            form = ''\n",
    "            #if we have image then give us the format\n",
    "            if img is not None:\n",
    "                img_format = image_path.split('.')[-1]\n",
    "                form = img_format\n",
    "            else:\n",
    "                print(\"Failed to read image\")\n",
    "            #if the form is not a valid extension then remove the image\n",
    "            if form not in image_exts:\n",
    "                print('Image is not in the extensions list{}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print('issue with image {}'.format(image_path))\n",
    "\n",
    "#makes it so we do not need to build labels or classes and will resize images \n",
    "#go into jupyter notebook to look at batch sizes and such. Can always pass these in as arguements after 'data'\n",
    "data = tf.keras.utils.image_dataset_from_directory('data')\n",
    "\n",
    "#converts data into numpy iterator\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "\n",
    "\n",
    "\n",
    "#PRE PROCESSING STEPS\n",
    "\n",
    "\n",
    "#scales our data to be betwwen 0 and 1 instead of 0 and 255\n",
    "# x is images and y is target variable\n",
    "data = data.map(lambda x,y: (x/255, y))\n",
    "\n",
    "#split the data between training and testing and validation\n",
    "\n",
    "\n",
    "train_size = int(len(data)*.7)\n",
    "val_size = 0\n",
    "test_size = 0 \n",
    "\n",
    "val_add = 0\n",
    "while train_size + val_size + test_size < len(data):\n",
    "    if val_add == 0:\n",
    "        val_size +=1\n",
    "        val_add+=1\n",
    "    else:\n",
    "        test_size +=1\n",
    "        val_add= 0\n",
    "    \n",
    "    \n",
    "print(train_size)\n",
    "print(val_size)\n",
    "print(test_size)\n",
    "print(len(data))\n",
    "\n",
    "\n",
    "#skip skips previously used images, takes takes images\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#DEEP MODEL\n",
    "model = Sequential()\n",
    "#uses filters to make a classification\n",
    "#relu means only see the positive values, makes all negative values 0\n",
    "model.add(Conv2D(16, (3,3), 1, activation = 'relu', input_shape = (256, 256, 3)))\n",
    "#takes max value\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#same things down here\n",
    "model.add(Conv2D(32, (3,3), 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#flattens the values\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "#maps betwwen 0 and 1 \n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "#adam is optimizer, we want to track accuracy\n",
    "model.compile('adam', loss= tf.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n",
    "\n",
    "#TRAIN THE NETWORK\n",
    "\n",
    "#logs our model training\n",
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir)\n",
    "\n",
    "#epochs are how many runs we do over a training set. we pass over our training data to run an evaluation on our evaluation data and we want to log our information to tensorboard\n",
    "hist = model.fit(train, epochs=20, validation_data = val, callbacks = [tensorboard_callback])\n",
    "\n",
    "#now we are totally trained\n",
    "\n",
    "#visual loss and data loss\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color = 'teal', label = 'loss')\n",
    "plt.plot(hist.history['val_loss'], color = 'red', label = 'val_loss')\n",
    "fig.suptitle('Loss', fontsize = 20)\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#visualize the accuracy\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color = 'teal', label = 'accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color = 'red', label = 'val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize = 20)\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#EVALUATE OUR PERFORMANCE/TEST\n",
    "\n",
    "#makes instances of classes we need\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()\n",
    "\n",
    "\n",
    "#Look out for these, says model is not good when it actually is working great\n",
    "for batch in test.as_numpy_iterator():\n",
    "    x, y = batch\n",
    "    #returns a value between 0 and 1 \n",
    "    yhat = model.predict(x)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)\n",
    "print(\"Tests on our test data stats: \")\n",
    "print(str(pre.result().numpy()) + \" = Precision result\")\n",
    "print(str(re.result().numpy()) + \" = Recall result\")\n",
    "print(str(acc.result().numpy()) + \" = Accuracy result\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)+1\n",
    "test_size = (int(len(data)*.1))+1\n",
    "\n",
    "all_size = (train_size+val_size+test_size)\n",
    "\n",
    "add_to_val = 0\n",
    "\n",
    "while all_size + 32 <= int(len(data)):\n",
    "    if add_to_val == 0:\n",
    "        val_size +=1\n",
    "    else:\n",
    "        test_size +=1\n",
    "        add_to_val +=1\n",
    "    all_size+=32\n",
    "\n",
    "print(train_size+val_size+test_size)\n",
    "print(int(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class 0 is basketball and class 1 is lacrosse\n",
    "batch = data_iterator.next()\n",
    "fig, ax = plt.subplots(ncols=4, figsize = (20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color = 'teal', label = 'loss')\n",
    "plt.plot(hist.history['val_loss'], color = 'red', label = 'val_loss')\n",
    "fig.suptitle('loss', fontsize = 20)\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color = 'teal', label = 'accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color = 'red', label = 'val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize = 20)\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tests on our test data stats: \")\n",
    "print(str(pre.result().numpy()) + \" = Precision result\")\n",
    "print(str(re.result().numpy()) + \" = Recall result\")\n",
    "print(str(acc.result().numpy()) + \" = Accuracy result\")\n",
    "\n",
    "print(pre.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows an image of an outside test\n",
    "img = cv2.imread('notb.jpeg')\n",
    "resize = tf.image.resize(img, (256,256))\n",
    "\n",
    "#adds an extra dimanesion as our model expects a batch of images not just 1\n",
    "#divided by 255 to scale it\n",
    "np.expand_dims(resize, 0)\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "\n",
    "label = ''\n",
    "print(yhat)\n",
    "if yhat >= .5:\n",
    "    label = 'This is a picture of lacrosse'\n",
    "else:\n",
    "    label = 'This is a picture of basketball'\n",
    "\n",
    "plt.title(label)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lacrosse_and_basketall_dir = 'lacrosse_and_basketball'\n",
    "\n",
    "for image in os.listdir(os.path.join(lacrosse_and_basketall_dir)):\n",
    "    #gets image path\n",
    "    image_path = os.path.join(lacrosse_and_basketall_dir, image)\n",
    "    try:\n",
    "        #reads in the image and creats a form variable that will give us some sort of .jpg .png etc\n",
    "        img = cv2.imread(image_path)\n",
    "        form = ''\n",
    "        #if we have image then give us the format\n",
    "        if img is not None:\n",
    "            img_format = image_path.split('.')[-1]\n",
    "            form = img_format\n",
    "        else:\n",
    "            print(\"Failed to read image\")\n",
    "        #if the form is not a valid extension then remove the image\n",
    "        if form not in image_exts:\n",
    "            print('Image is not in the extensions list{}'.format(image_path))\n",
    "            os.remove(image_path)\n",
    "    except Exception as e:\n",
    "        print('issue with image {}'.format(image_path))\n",
    "\n",
    "for image in os.listdir(os.path.join(lacrosse_and_basketall_dir)):\n",
    "    #gets image path\n",
    "    image_path = os.path.join(lacrosse_and_basketall_dir, image)\n",
    "    img = cv2.imread(image_path)\n",
    "    resize = tf.image.resize(img, (256,256))\n",
    "\n",
    "    #adds an extra dimanesion as our model expects a batch of images not just 1\n",
    "    #divided by 255 to scale it\n",
    "    np.expand_dims(resize, 0)\n",
    "    yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "\n",
    "    #makes our save location\n",
    "    save_location = ''\n",
    "   \n",
    "    if yhat >= .5:\n",
    "        save_location = 'sortedLacrosse'\n",
    "    else:\n",
    "        save_location = 'sortedBasketball'\n",
    "\n",
    "    \n",
    "    # create the full file path by combining the folder path and file name\n",
    "    file_path = os.path.join(save_location, image)\n",
    "\n",
    "    # saves img to specified location\n",
    "    cv2.imwrite(file_path, img)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
